{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b12a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88994a29",
   "metadata": {},
   "source": [
    "### Project Outline - Shared Document\n",
    "https://docs.google.com/document/d/1gZ5QkT95D7WJ8sPUyC0qURUVcKZQrPub2nR4gyRYPkc/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf1f6e",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b1a33c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hate_crime.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14124/1284933848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhate_crime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hate_crime.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print shape and first 5 rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhate_crime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhate_crime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hate_crime.csv'"
     ]
    }
   ],
   "source": [
    "hate_crime = pd.read_csv('hate_crime.csv')\n",
    "\n",
    "#print shape and first 5 rows\n",
    "print(hate_crime.shape)\n",
    "hate_crime.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41db652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#datatypes and null count\n",
    "hate_crime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year range\n",
    "hate_crime['DATA_YEAR'].agg([np.max, np.min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract Population Group Description to use later\n",
    "population_groups = hate_crime[['POPULATION_GROUP_CODE', 'POPULATION_GROUP_DESC']].value_counts()\n",
    "population_groups_df = pd.DataFrame(population_groups).sort_values('POPULATION_GROUP_CODE').reset_index()\n",
    "population_groups_df = population_groups_df[['POPULATION_GROUP_CODE', 'POPULATION_GROUP_DESC']]\n",
    "population_groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c68e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Location / Population Data Exploration\n",
    "fig = plt.plot()\n",
    "hate_crime['STATE_ABBR'].hist(figsize=(10,10))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.suptitle('STATE_ABBR')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20,20))\n",
    " \n",
    "hate_crime['DATA_YEAR'].hist(ax=axes[0,0])\n",
    "plt.sca(axes[0,0])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('DATA_YEAR', fontsize=20)\n",
    "\n",
    "hate_crime['POPULATION_GROUP_CODE'].hist(ax=axes[0,1])\n",
    "plt.sca(axes[0,1])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('POPULATION_GROUP_CODE', fontsize=20)\n",
    "\n",
    "hate_crime['DIVISION_NAME'].hist(ax=axes[1,0])\n",
    "plt.sca(axes[1,0])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('DIVISION_NAME', fontsize=20)\n",
    "\n",
    "hate_crime['REGION_NAME'].hist(ax=axes[1,1])\n",
    "plt.sca(axes[1,1])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('REGION_NAME', fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Observations - States, Regions, Divisions are likley skewed by population, look at correlation with population descriptions\n",
    "#US Territories and Other can be dropped from REgion/Division due to small sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OFFENDER / VICTIM DATA EXPLORATION\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20,20))\n",
    "\n",
    "hate_crime['TOTAL_OFFENDER_COUNT'].hist(ax=axes[0,0])\n",
    "plt.sca(axes[0,0])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('TOTAL_OFFENDER_COUNT', fontsize=20)\n",
    "\n",
    "hate_crime['VICTIM_COUNT'].hist(ax=axes[0,1])\n",
    "plt.sca(axes[0,1])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('VICTIM_COUNT', fontsize=20)\n",
    "\n",
    "\n",
    "hate_crime['MULTIPLE_OFFENSE'].hist(ax=axes[1,0])\n",
    "plt.sca(axes[1,0])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('MULTIPLE_OFFENSE', fontsize=20)\n",
    "\n",
    "hate_crime['MULTIPLE_BIAS'].hist(ax=axes[1,1])\n",
    "plt.sca(axes[1,1])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('MULTIPLE_BIAS', fontsize=20)\n",
    "\n",
    "\n",
    "hate_crime['OFFENDER_RACE'].hist(ax=axes[2,0])\n",
    "plt.sca(axes[2,0])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('OFFENDER_RACE', fontsize=20)\n",
    "\n",
    "hate_crime['TOTAL_INDIVIDUAL_VICTIMS'].hist(ax=axes[2,1])\n",
    "plt.sca(axes[2,1])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('TOTAL_INDIVIDUAL_VICTIMS', fontsize=20)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "##Observations - Offender and Vistim count that are much larger that average should be considered outliers and removed\n",
    "#Multiple Offense/Multiple Bias have too few observations in the multiple category & should be removed\n",
    "# Total_Individual_Victims and Victim_count have conflicting meaning, seems liek Victim Coiunt is more accurate, more explorationg needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.plot()\n",
    "hate_crime['VICTIM_TYPES'].hist(figsize=(10,10))\n",
    "plt.xticks(rotation='vertical', fontsize=10)\n",
    "plt.suptitle('VICTIM_TYPES')\n",
    "plt.show()\n",
    "\n",
    "## Observations - The vast majority of categories for VICTIM_TYPE, LOCATION NAME and BIAS DESCRIPTION\n",
    " # are redundant, many categories can be combined into the top 10-15 for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20,20))\n",
    "\n",
    "hate_crime['VICTIM_TYPES'].hist(ax=axes[0])\n",
    "plt.sca(axes[0])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('VICTIM_TYPES', fontsize=20)\n",
    "\n",
    "hate_crime['LOCATION_NAME'].hist(ax=axes[1])\n",
    "plt.sca(axes[1])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('LOCATION_NAME', fontsize=20)\n",
    "\n",
    "hate_crime['BIAS_DESC'].hist(ax=axes[2])\n",
    "plt.sca(axes[2])\n",
    "plt.xticks(rotation='vertical', fontsize=18)\n",
    "plt.title('BIAS_DESC', fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## Observations - The vast majority of categories for VICTIM_TYPE, LOCATION NAME and BIAS DESCRIPTION\n",
    " # are redundant, many categories can be combined into the top 10-15 for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a572b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# political climate csv\n",
    "political = pd.read_csv('political_climate.csv')\n",
    "political"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f062e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43abea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicate columns like state name and unnecessary columns like Agency Name\n",
    "hate_crime = hate_crime.drop(['STATE_NAME', 'POPULATION_GROUP_DESC', 'PUB_AGENCY_UNIT', \n",
    "                              'ORI', 'PUB_AGENCY_NAME', 'AGENCY_TYPE_NAME', \n",
    "                              'TOTAL_INDIVIDUAL_VICTIMS','DIVISION_NAME', 'INCIDENT_ID', \n",
    "                              'MULTIPLE_OFFENSE', 'MULTIPLE_BIAS'], axis=1)\n",
    "hate_crime.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58866a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking null values\n",
    "\n",
    "percent_missing = hate_crime.isnull().sum() *100/len(hate_crime)\n",
    "missing_values_df = pd.DataFrame({'column_name': hate_crime.columns, 'percent_missing': percent_missing})\n",
    "missing_values_df.sort_values('percent_missing', inplace = True)\n",
    "display(missing_values_df)\n",
    "\n",
    "#drop columns with more than 70% missing values\n",
    "perc = 70.0\n",
    "min_count = int(((100-perc)/100)*hate_crime.shape[0]+1)\n",
    "hate_crime = hate_crime.dropna(axis=1, thresh=min_count)\n",
    "\n",
    "#checking remaining missing values\n",
    "hate_crime.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f516f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace null values in OFFENDER RACE column\n",
    "\n",
    "#view unique values\n",
    "unique_race_cat = hate_crime['OFFENDER_RACE'].unique()\n",
    "print(unique_race_cat)\n",
    "\n",
    "#replace nan with unknown label\n",
    "hate_crime['OFFENDER_RACE'] = hate_crime['OFFENDER_RACE'].replace(np.nan, 'Unknown')\n",
    "hate_crime['OFFENDER_RACE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed50bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifying no missing values\n",
    "hate_crime.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af16a7c",
   "metadata": {},
   "source": [
    "### Transforming Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to datetime\n",
    "hate_crime[\"INCIDENT_DATE\"] = pd.to_datetime(hate_crime[\"INCIDENT_DATE\"])\n",
    "hate_crime.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290e9996",
   "metadata": {},
   "source": [
    "### Reducing Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcde373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the number of categories for the following:\n",
    "print(hate_crime['VICTIM_TYPES'].unique())\n",
    "print()\n",
    "print(hate_crime['LOCATION_NAME'].unique())\n",
    "print()\n",
    "print(hate_crime['BIAS_DESC'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce the number of categories for VICTIM_TYPES by condensing labels\n",
    "replacements = {'VICTIM_TYPES':{r'.*Law Enforcement Officer.*':'Law Enforcement Officer', \n",
    "                                r'.*Religious Organization.*': 'Religious Organization', \n",
    "                                r'.*Business.*': 'Business', \n",
    "                                r'.*Government.*': 'Government', \n",
    "                                r'.*Individual.*': 'Individual', \n",
    "                                r'.*Society/Public.*':'Society/Public'}}\n",
    "hate_crime.replace(replacements, regex=True, inplace=True)\n",
    "\n",
    "hate_crime['VICTIM_TYPES'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056e409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reduce the number of categories for LOCATION_NAME by condensing labels\n",
    "replacements = {'LOCATION_NAME':{r'.*Highway/Road/Alley/Street/Sidewalk.*':'Highway/Road/Alley/Street/Sidewalk', \n",
    "                                 r'.*College.*': 'School-College/University', \n",
    "                                 r'.*Residence/Home.*': 'Residence/Home',\n",
    "                                 r'.*Drug Store/Doctor.*': 'Drug Store/Doctor', \n",
    "                                 r'.*Commercial/Office Building.*': 'Commercial/Office Building',\n",
    "                                 r'.*Restaurant.*': 'Restaurant', \n",
    "                                 r'.*Government/Public Building.*': 'Government/Public Building',\n",
    "                                 r'.*Grocery/Supermarket.*': 'Grocery/Supermarket',\n",
    "                                 r'.*Parking/Drop Lot/Garage.*': 'Parking/Drop Lot/Garage',\n",
    "                                 r'.*Jail/Prison/Penitentiary/Corrections Facility.*': 'Jail/Prison/Penitentiary/Corrections Facility',  \n",
    "                                 r'.*School-Elementary/Secondary.*': 'School-Elementary/Secondary', \n",
    "                                 r'.*Church/Synagogue/Temple/Mosque.*': 'Church/Synagogue/Temple/Mosque', \n",
    "                                 r'.*Amusement Park.*': 'Amusement Park',\n",
    "                                 r'.*Bar/Nightclub.*': 'Bar/Nightclub',\n",
    "                                 r'.*Air/Bus/Train Terminal.*': 'Air/Bus/Train Terminal',\n",
    "                                 r'.*Department/Discount Store.*': 'Department/Discount Store',\n",
    "                                 r'.*Auto Dealership New/Used.*': 'Auto Dealership New/Used'\n",
    "                                }}\n",
    "hate_crime.replace(replacements, regex=True, inplace=True)\n",
    "\n",
    "hate_crime['LOCATION_NAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce the number of categories for BIAS_DESC by condensing labels\n",
    "replacements = {'BIAS_DESC':{r'.*Anti-Black.*':'Anti-Black or African American', \n",
    "                             r'.*Anti-Jewish.*': 'Anti-Jewish', \n",
    "                             r'.*Anti-Gay.*': 'Anti-Gay (Male)',\n",
    "                             r'.*Anti-Lesbian.*': 'Anti-Lesbian (Female)', \n",
    "                             r'.*Anti-Islamic.*': 'Anti-Islamic (Muslim)',\n",
    "                             r'.*Anti-Hispanic.*': 'Anti-Hispanic or Latino',\n",
    "                             r'.*Anti-Transgender.*': 'Anti-Transgender', \n",
    "                             r'.*Anti-Gender Non-Conforming.*': 'Anti-Gender Non-Conforming',\n",
    "                             r'.*Anti-Asian.*': 'Anti-Asian',\n",
    "                             r'.*Anti-Bisexual,*':'Anti-Bisexual',\n",
    "                             r'.*Anti-American Indian.*': 'Anti-Native American',\n",
    "                             r'.*Anti-Mental Disability.*': 'Anti-Mental Disability',\n",
    "                             r'.*Anti-Physical Disability.*': 'Anti-Physical Disability',\n",
    "                             r'.*Anti-Other Religion.*': 'Anti-Other Religion', \n",
    "                             r'.*Anti-Multiple Races, Group.*': 'Anti-Multiple Races, Group', \n",
    "                             r'.*Anti-Hindu.*': 'Anti-Hindu', \n",
    "                             r'.*Anti-Catholic.*': 'Anti-Catholic', \n",
    "                             r'.*Anti-Arab.*': 'Anti-Arab', \n",
    "                             r'.*Anti-Jehovah.*': 'Anti-Jehovahs Witness', \n",
    "                             r'.*Anti-White.*': 'Anti-White',\n",
    "                             r'.*Anti-Multiple Religions.*': 'Anti-Multiple Religions',\n",
    "                             r'.*Anti-Protestant.*': 'Anti-Protestant',\n",
    "                             r'.*Anti-Native Hawaiian.*': 'Anti-Native Hawaiian or Other Pacific Islander',\n",
    "                             r'.*Anti-Bisexual.*': 'Anti-Bisexual', \n",
    "                             r'.*Anti-Female.*': 'Anti-Female'\n",
    "                            }}\n",
    "hate_crime.replace(replacements, regex=True, inplace=True)\n",
    "\n",
    "hate_crime['BIAS_DESC'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff55e3",
   "metadata": {},
   "source": [
    "### Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be encoded:\n",
    "# STATE_ABBR, REGION_NAME, POPULATION_GROUP_CODE, OFFENDER_RACE, \n",
    "# OFFENSE_NAME, LOCATION_NAME, BIAS_DESC, VICTIM_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a766ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in hate_crime:\n",
    "    if (hate_crime[col].dtypes) == object:\n",
    "        print(col, hate_crime[col].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in hate_crime:\n",
    "    if (hate_crime[col].dtypes) == object:\n",
    "        hate_crime[col] = hate_crime[col].astype('category')\n",
    "        hate_crime[col] = hate_crime[col].cat.codes     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_crime.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9fa5f5",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c194ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_crime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17040dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hate_crime_backup_df = hate_crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f567fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hate_crime.drop('INCIDENT_DATE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized = Normalizer().fit_transform(hate_crime)\n",
    "\n",
    "#turn the output array into a dataframe\n",
    "#normalized_df = pd.DataFrame(normalized, columns = hate_crime_backup_df.columns)\n",
    "#normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5620141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a8890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8f783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b02c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
